# -*- coding: utf-8 -*-
"""RandomForestPRML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xxao6yYoxJq1xkpH1AKZFuLABRTlySqN
"""
import joblib
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.model_selection import train_test_split
np.random.seed(42)
df = pd.read_csv("Train_data.csv")

# Encode all object columns (except class, which weâ€™ll handle separately)
def le_all(df):
    for col in df.columns:
        if col != 'class' and df[col].dtype == 'object':
            encoder = LabelEncoder()
            df[col] = encoder.fit_transform(df[col])

le_all(df)

# Now handle the 'class' column separately and keep the encoder
class_encoder = LabelEncoder()
df["class"] = class_encoder.fit_transform(df["class"])

# Print the mapping
label_mapping = dict(zip(class_encoder.classes_, class_encoder.transform(class_encoder.classes_)))
print("Class label mapping:", label_mapping)
x=  df.drop("class",axis= 1)
y= df["class"]
x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.2, random_state= 42)

from collections import Counter

class MyRandomForest:
    def __init__(self, n_trees=10,sample_ratio=0.3, max_depth=None, n_features=None):
        self.n_trees = n_trees
        self.max_depth = max_depth
        self.sample_ratio = sample_ratio
        self.n_features = n_features
        self.trees = []

    def bootstrap_sample(self, X, y):
        n_samples = X.shape[0]
        indices = np.random.choice(n_samples, int(n_samples* self.sample_ratio), replace=True)
        return X.iloc[indices], y.iloc[indices]

    def fit(self, X, y):
        self.trees = []
        for _ in range(self.n_trees):
            X_sample, y_sample = self.bootstrap_sample(X, y)
            tree = DecisionTreeClassifier(
                max_depth=self.max_depth,
                max_features=self.n_features,
                # random_state= 42
            )
            tree.fit(X_sample, y_sample)
            # plt.figure(figsize=(30, 20))
            # plot_tree(tree)
            # plt.show()
            self.trees.append(tree)

    def predict(self, X):
        tree_predictions = np.array([tree.predict(X) for tree in self.trees])
        final_predictions = []

        for sample_preds in tree_predictions.T:
            # Majority vote
            vote = Counter(sample_preds).most_common(1)[0][0]
            final_predictions.append(vote)

        return np.array(final_predictions)

# best_sample, best_trees, best_depth = grid_search_rf(x, y, sample_ratios, n_trees_options, max_depths)
best_sample=0.5
best_trees= 15
best_depth = None
final_model = MyRandomForest(n_trees=best_trees, sample_ratio=best_sample, max_depth=best_depth)
final_model.fit(x_train, y_train)


joblib.dump(final_model, "python_models/models/RF_models/random_forest.pkl")
# print(f"Final Model Accuracy: {final_acc:.4f}")
